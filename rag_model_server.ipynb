{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_core langchain_community langchain langchain_pinecone jq pypdf bs4 pandas numpy pinecone-client datasets ragas\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"921f776d-0d66-4d45-8026-5eea98f28936\"\n",
    "os.environ[\"PINECONE_API_ENV\"] = \"us-east-1\"\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an AI assistant, trained to provide understandable and accurate information about pharmacogenomics and drugs.\n",
    "You will base your responses on the context and information provided. Output both your answer and a score of how confident you are,\n",
    " and also cite the references. Also provide the source of the chunks of the documents used for response.\n",
    "If the information related to the question is not in the context and or in the information provided in the prompt, \n",
    "you will say 'I don't know'.\n",
    "You are not a healthcare provider and you will not provide medical care or make assumptions about treatment.\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "folder_path = \"/home/dhanushb/Wellytics/RAG_data/all_files\"\n",
    "jsondata = []\n",
    "csvdata = []\n",
    "pdfdocs = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        doc = loader.load()\n",
    "        pdfdocs.extend(doc)\n",
    "    elif filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        loader = CSVLoader(file_path)\n",
    "        data = loader.load()\n",
    "        csvdata.extend(data)\n",
    "    elif filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        loader = JSONLoader(file_path, jq_schema=\".\",json_lines=False,text_content=False)\n",
    "        data = loader.load()\n",
    "        jsondata.extend(data)\n",
    "\n",
    "for doc in pdfdocs:\n",
    "    doc.page_content = doc.page_content.replace('\\t', ' ')\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=1000)\n",
    "documents = text_splitter.split_documents(pdfdocs)\n",
    "jsondocs = text_splitter.split_documents(jsondata)\n",
    "\n",
    "documents += jsondocs + csvdata \n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "vectorstore = Pinecone.from_documents(documents, embedding=embeddings, index_name=\"rag-data\")\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(embedding=embeddings, index_name=\"rag-data\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Questions = pd.read_csv(\"/home/dhanushb/Wellytics/RAG_data/Questions.csv\")\n",
    "\n",
    "questions = Questions[\"Questions\"].to_list()\n",
    "\n",
    "cont = []\n",
    "for question in questions:\n",
    "    cont.append([docs.page_content for docs in retriever.invoke(question)])\n",
    "Questions[\"Context\"] = cont\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "MODELS = [\"mistral\", \"gemma\", \"llama2\", \"llama3\"]\n",
    "\n",
    "for MODEL in MODELS:\n",
    "    model = Ollama(model=MODEL)\n",
    "    chain = setup | prompt | model | parser\n",
    "    resp = []\n",
    "    n = len(questions)\n",
    "    i = 1\n",
    "    for question in questions:\n",
    "        resp.append(chain.invoke(question))\n",
    "        Questions[MODEL + \"_resp\"] = resp + [np.nan] * (n - i)\n",
    "        Questions.to_csv(\"/home/dhanushb/Wellytics/RAG_data/Questions.csv\")\n",
    "        i += 1\n",
    "\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics.critique import harmfulness, strictness, \n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_relevancy,\n",
    "    answer_similarity,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "quests = Questions[Questions[\"Expected_response\"].notna()]\n",
    "\n",
    "for MODEL in MODELS:\n",
    "\n",
    "    # To dict\n",
    "    data = {\n",
    "        \"question\": list(map(str, quests[\"Questions\"].to_list())),\n",
    "        \"answer\": list(map(str, quests[MODEL + \"_resp\"].to_list())),\n",
    "        \"contexts\": [[str(context)] for context in quests[\"context\"].to_list()],\n",
    "        \"ground_truth\": list(map(str, quests[\"Expected_response\"].to_list()))\n",
    "    }\n",
    "\n",
    "    # Convert dict to dataset\n",
    "    dataset = Dataset.from_dict(data)\n",
    "\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            context_entity_recall,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "            harmfulness\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    df = result.to_pandas()\n",
    "\n",
    "    df.to_csv(\"/home/dhanushb/Wellytics/RAG_data/\" + MODEL + \"_eval.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
